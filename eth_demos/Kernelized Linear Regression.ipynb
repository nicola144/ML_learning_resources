{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Kernelized Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "% reload_ext autoreload\n",
    "% load_ext autoreload\n",
    "% autoreload 2 \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from util import gradient_descent\n",
    "import plot_helpers\n",
    "import IPython \n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10, 5)\n",
    "\n",
    "from kernels import LinearKernel, PolynomialKernel, LaplacianKernel, GaussianKernel, PeriodicKernel\n",
    "from kernels import SumKernel\n",
    "from regularizers import L2Regularizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100\n",
    "xmin = 0\n",
    "xmax = 10\n",
    "noise = 0.2\n",
    "X = np.reshape(np.linspace(xmin, xmax, num_points), [-1, 1])  # create 1-D input data\n",
    "F = X + np.sin(X * 5) - np.cos(X * 10)  # true functional response\n",
    "Y = F + noise * np.random.randn(num_points, 1)  # generate noisy labels\n",
    "\n",
    "# Training Data\n",
    "training_idx = np.arange(0, 50, 2)\n",
    "Xtr = X[training_idx, :]\n",
    "Ytr = Y[training_idx]\n",
    "\n",
    "# Test Data\n",
    "test_idx = np.setdiff1d(np.arange(0, num_points, 1), training_idx)\n",
    "Xtest = X[test_idx, :]\n",
    "Ytest = Y[test_idx]\n",
    "\n",
    "fig = plt.subplot(111)\n",
    "opt = {'marker': 'r*', 'label': 'Training data'}\n",
    "plot_helpers.plot_data(Xtr, Ytr, fig=fig, options=opt)\n",
    "opt = {'marker': 'bo', 'label': 'Test data'}\n",
    "plot_helpers.plot_data(Xtest, Ytest, fig=fig, options=opt)\n",
    "opt = {'marker': 'k-', 'label': 'True Function', 'x_label': '$x$', 'y_label': '$y$', 'legend': True}\n",
    "plot_helpers.plot_data(X, F, fig=fig, options=opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_regression(kernel, reg, deg, kernel_width):\n",
    "    reg = np.power(10., reg)\n",
    "    if kernel == 'Linear':\n",
    "        regressor = LinearKernel(Xtr, Ytr, reg=reg)\n",
    "    elif kernel == 'Polynomial':\n",
    "        regressor = PolynomialKernel(Xtr, Ytr, deg=deg, reg=reg)\n",
    "    elif kernel == 'Laplacian':\n",
    "        regressor = LaplacianKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    elif kernel == 'Gaussian':\n",
    "        regressor = GaussianKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    elif kernel == 'Periodic':\n",
    "        regressor = PeriodicKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    elif kernel == 'Poly + Gaussian':\n",
    "        regressor = SumKernel([GaussianKernel, PolynomialKernel], Xtr, Ytr, reg=reg, deg=deg, bw=kernel_width)\n",
    "        # regressor = GaussianPolyKernel(Xtr, Ytr, reg=reg, deg=deg, bw=kernel_width)\n",
    "    elif kernel == 'Poly + Periodic':\n",
    "        regressor = SumKernel([PeriodicKernel, PolynomialKernel], Xtr, Ytr, reg=reg, deg=deg, bw=kernel_width)\n",
    "#         regressor = PeriodicPolyKernel(Xtr, Ytr, reg=reg, deg=deg, bw=kernel_width)\n",
    "\n",
    "    regressor.calculate_alpha(Ytr)\n",
    "    ypr = regressor.predict(X)\n",
    "\n",
    "    fig = plt.subplot(111)\n",
    "    opt = {'marker': 'r*', 'label': 'Training data'}\n",
    "    plot_helpers.plot_data(Xtr, Ytr, fig=fig, options=opt)\n",
    "    opt = {'marker': 'bo', 'label': 'Test data'}\n",
    "    plot_helpers.plot_data(Xtest, Ytest, fig=fig, options=opt)\n",
    "    opt = {'marker': 'g-', 'label': kernel + ' Kernel', 'x_label': '$x$', 'y_label': '$y$', 'legend': True}\n",
    "    plot_helpers.plot_data(X, ypr, fig=fig, options=opt)\n",
    "    fig.set_xlim([-1, 11])\n",
    "    fig.set_ylim([-1, 11])\n",
    "\n",
    "interact(kernel_regression,\n",
    "         kernel=ipywidgets.RadioButtons(\n",
    "             options=['Linear', 'Polynomial', 'Laplacian', 'Gaussian', 'Periodic', 'Poly + Gaussian', 'Poly + Periodic'],\n",
    "             value='Linear',\n",
    "             description='Kernel type:',\n",
    "             style={'description_width': 'initial'}),\n",
    "         reg=ipywidgets.FloatSlider(\n",
    "             value=-2,\n",
    "             min=-3,\n",
    "             max=3,\n",
    "             step=1e-3,\n",
    "             readout_format='.3f',\n",
    "             description='Regularization 10^:',\n",
    "             style={'description_width': 'initial'},\n",
    "             continuous_update=False),\n",
    "         deg = ipywidgets.IntSlider(\n",
    "             value=1,\n",
    "             min=1,\n",
    "             max=10, \n",
    "             step=1,\n",
    "             description='Degree of Polynomial kernel:',\n",
    "             style={'description_width': 'initial'}),\n",
    "         kernel_width=ipywidgets.FloatSlider(\n",
    "             value=0.2,\n",
    "             min=0.01,\n",
    "             max=3,\n",
    "             step=0.01,\n",
    "             readout_format='.3f',\n",
    "             description='Kernel Width:',\n",
    "             style={'description_width': 'initial'},\n",
    "             continuous_update=False),\n",
    "         );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_variation(kernel, reg=0.05, kernel_width=5):\n",
    "    if kernel == 'Laplacian':\n",
    "        regressor = LaplacianKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    elif kernel == 'Gaussian':\n",
    "        regressor = GaussianKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    elif kernel == 'Periodic':\n",
    "        regressor = PeriodicKernel(Xtr, Ytr, reg=reg, bw=kernel_width)\n",
    "    regressor.calculate_alpha(Ytr)\n",
    "    ypr = regressor.predict(X)\n",
    "    \n",
    "    fig = plt.subplot(111)\n",
    "    opt = {'marker': 'r*', 'label': 'Training data'}\n",
    "    plot_helpers.plot_data(Xtr, Ytr, fig=fig, options=opt)\n",
    "    opt = {'marker': 'bo', 'label': 'Test data'}\n",
    "    plot_helpers.plot_data(Xtest, Ytest, fig=fig, options=opt)\n",
    "\n",
    "    opt = {'marker': 'g-', 'label': 'Gaussian Kernel', 'x_label': '$x$', 'y_label': '$y$', 'legend': True}\n",
    "    plot_helpers.plot_data(X, ypr, fig=fig, options=opt)\n",
    "\n",
    "\n",
    "interact(parameter_variation,\n",
    "         kernel=ipywidgets.RadioButtons(\n",
    "             options=['Laplacian', 'Gaussian', 'Periodic'],\n",
    "             value='Gaussian',\n",
    "             description='Kernel type:',\n",
    "             style={'description_width': 'initial'}),\n",
    "         kernel_width=ipywidgets.FloatSlider(\n",
    "             value=0.2,\n",
    "             min=0.01,\n",
    "             max=3,\n",
    "             step=0.01,\n",
    "             readout_format='.3f',\n",
    "             description='Kernel Width:',\n",
    "             style={'description_width': 'initial'},\n",
    "             continuous_update=False),\n",
    "         reg=ipywidgets.FloatSlider(\n",
    "             value=1e-2,\n",
    "             min=0,\n",
    "             max=1,\n",
    "             step=1e-3,\n",
    "             readout_format='.3f',\n",
    "             description='Regularization Coefficient:',\n",
    "             style={'description_width': 'initial'},\n",
    "             continuous_update=False)\n",
    "         );\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = GaussianKernel(Xtr, Ytr, reg=0.0, bw=0.2)\n",
    "regularizer = L2Regularizer(0)\n",
    "alpha0 = np.random.randn(Xtr.shape[0])\n",
    "\n",
    "opts = {'eta0': 1,\n",
    "        'n_iter': 50,\n",
    "        'batch_size': 5,\n",
    "        'n_samples': Xtr.shape[0],\n",
    "        'algorithm': 'SGD',\n",
    "        'learning_rate_scheduling': None\n",
    "        }\n",
    "alphas, indexes = gradient_descent(alpha0, regressor, regularizer, opts)\n",
    "\n",
    "fig = plt.subplot(111)\n",
    "opt = {'marker': 'r*', 'label': 'Training data'}\n",
    "plot_helpers.plot_data(Xtr, Ytr, fig=fig, options=opt)\n",
    "opt = {'marker': 'bo', 'label': 'Test data'}\n",
    "plot_helpers.plot_data(Xtest, Ytest, fig=fig, options=opt)\n",
    "\n",
    "opt = {'marker': 'g-', 'label': 'Gaussian Kernel', 'x_label': '$x$', 'y_label': '$y$', 'legend': True, 'sgd_point': True}\n",
    "plot_helpers.kernelized_regression_progression(X, Xtr, Ytr, alphas, indexes, regressor, fig=fig, options=opt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
